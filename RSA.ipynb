{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RDMs analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RDMs plotting methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-23T15:03:01.196579Z",
     "start_time": "2025-06-23T15:03:01.186347Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from itertools import combinations\n",
    "\n",
    "\n",
    "def join_layers(task_rdms, layer, models):\n",
    "    joined_rdms = {}\n",
    "    for model in models:\n",
    "        model_rdms = task_rdms[model]\n",
    "        training_modes = models[model]\n",
    "        for training_mode in training_modes:\n",
    "            training_mode_rdm = model_rdms[training_mode]\n",
    "            if layer not in training_mode_rdm:\n",
    "                continue\n",
    "            joined_rdms[f'{model}_{training_mode}'] = training_mode_rdm[layer]\n",
    "    return joined_rdms\n",
    "\n",
    "\n",
    "def base_name(model_name):\n",
    "    basename = model_name.split('_')[0]\n",
    "    if basename == 'bmi':\n",
    "        return 'BMI'\n",
    "    elif basename == 'baseline':\n",
    "        return 'Voxel Representation'\n",
    "    return basename.capitalize() \n",
    "\n",
    "\n",
    "def plot_model_comparisons(comparisons_dict, model_type, layers='all', x_label='Layers', group_by='layer', legend=True, title=None,\n",
    "                           fig_size=(10, 8)):\n",
    "    \"\"\"\n",
    "    Plot correlation comparisons between models using strip plots with confidence intervals.\n",
    "    \n",
    "    Parameters:\n",
    "    comparisons_dict: Dictionary with structure model1 -> model2 -> layer -> correlations\n",
    "    model_type: Either 'pretrained' or 'tl' to specify which model versions to compare\n",
    "    \"\"\"\n",
    "    models = [key for key in comparisons_dict.keys() if key.endswith(f'_{model_type}')]\n",
    "    if model_type == 'tl':\n",
    "        models += [f'baseline_{model_type}']\n",
    "    model_pairs = list(combinations(models, 2))\n",
    "    # order the model pairs to ensure \"none\" comparisons are first, then the others and finally the baseline\n",
    "    model_pairs = sorted(model_pairs, key=lambda x: ('none' in x[0].lower(), 'none' in x[1].lower(), x[0], x[1]))\n",
    "    # ensure baseline is always last\n",
    "    model_pairs = [pair for pair in model_pairs if 'baseline' not in pair[0] and 'baseline' not in pair[1]] + \\\n",
    "                  [pair for pair in model_pairs if 'baseline' in pair[0] or 'baseline' in pair[1]]\n",
    "    \n",
    "    if layers == 'all':\n",
    "        first_comparison = next(iter(comparisons_dict.values()))\n",
    "        first_layer_dict = next(iter(first_comparison.values()))\n",
    "        layers = list(first_layer_dict.keys())\n",
    "    if not isinstance(layers, list):\n",
    "        raise ValueError(\"Layers should be a list of layer names or 'all' to use all available layers.\")\n",
    "    \n",
    "    data_rows = []\n",
    "    for layer in layers:\n",
    "        for model1, model2 in model_pairs:            \n",
    "            if model1 in comparisons_dict and model2 in comparisons_dict[model1]:\n",
    "                correlations = comparisons_dict[model1][model2][layer]\n",
    "            elif model2 in comparisons_dict and model1 in comparisons_dict[model2]:\n",
    "                correlations = comparisons_dict[model2][model1][layer]\n",
    "            else:\n",
    "                continue\n",
    "            \n",
    "            comparison = f\"{base_name(model1)} vs {base_name(model2)}\"\n",
    "            if 'none' in model1.lower() or 'none' in model2.lower():\n",
    "                group = 'non-pretrained'\n",
    "            elif 'baseline' in model1.lower() or 'baseline' in model2.lower():\n",
    "                group = 'voxel model'\n",
    "            else:\n",
    "                group = 'pretrained'\n",
    "            for corr in correlations:\n",
    "                data_rows.append({\n",
    "                    'layer': layer,\n",
    "                    'comparison': comparison,\n",
    "                    'correlation': corr,\n",
    "                    'group': group\n",
    "                })\n",
    "    \n",
    "    df = pd.DataFrame(data_rows)\n",
    "    color_map = sns.color_palette(\"deep\")\n",
    "    sns.set_style('whitegrid')\n",
    "    fig = plt.figure(figsize=fig_size)\n",
    "    \n",
    "    if group_by == 'layer':\n",
    "        x = 'layer'\n",
    "    else:\n",
    "        x = 'group'\n",
    "\n",
    "    ax = sns.boxplot(data=df, x=x, y='correlation', hue='comparison', linewidth=1.5, \n",
    "                palette=color_map, fliersize=0.0, legend=legend)\n",
    "    sns.stripplot(data=df, x=x, y='correlation', hue='comparison', alpha=0.4, size=4, \n",
    "                  jitter=True, palette=color_map, dodge=True, ax=ax, legend=legend)\n",
    "\n",
    "    ax.set_xlabel(x_label, fontsize=15)\n",
    "    ax.set_ylabel('Correlation Values', fontsize=15)\n",
    "    if title:\n",
    "        ax.set_title(title, fontsize=16)\n",
    "    else:\n",
    "        ax.set_title(f'{model_type.capitalize()} modalities', fontsize=16)\n",
    "    sns.despine(ax=ax, left=True)\n",
    "    \n",
    "    min_value = round(df['correlation'].min() - 0.05, 1)\n",
    "    plt.yticks(np.arange(min_value, 1.01, 0.1))\n",
    "\n",
    "    if legend:\n",
    "        handles, labels = ax.get_legend_handles_labels()\n",
    "        n_comparisons = len(model_pairs)\n",
    "        ax.legend(handles[:n_comparisons], labels[:n_comparisons], ncol=n_comparisons,\n",
    "                title='Comparisons', loc='lower center', # bbox_to_anchor=(1.05, 1)\n",
    "                )\n",
    "    \n",
    "    fig.patch.set_alpha(0.0)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    return fig\n",
    "\n",
    "def parse_task_name(task):\n",
    "    if task == 'ad_vs_hc':\n",
    "        return 'AD vs HC'\n",
    "    elif task == 'ad_vs_mci':\n",
    "        return 'AD vs MCI'\n",
    "    elif task == 'mci_vs_hc':\n",
    "        return 'MCI vs HC'\n",
    "    return task\n",
    "\n",
    "def plot_representational_shifts(representational_shifts):\n",
    "    sns.set_theme()\n",
    "    models = [m.lower() for m in representational_shifts.keys()]\n",
    "    tasks = list(next(iter(representational_shifts.values())).keys())\n",
    "    colors = sns.color_palette(n_colors=len(models))\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(5, 4))\n",
    "    x = np.arange(len(tasks))\n",
    "\n",
    "    # Plot each model (no lines, just points)\n",
    "    for i, model in enumerate(models):\n",
    "        y = [representational_shifts[model][task][0] for task in tasks]\n",
    "        yerr = [representational_shifts[model][task][1] for task in tasks]\n",
    "        model_label = f'{model.capitalize()} finetuned' if model != 'bmi' else 'BMI finetuned'\n",
    "        ax.errorbar(x, y, yerr=yerr, elinewidth=4, fmt='o', color=colors[i], label=model_label, capsize=5, markersize=6, alpha=0.8)\n",
    "\n",
    "    ax.set_ylim(bottom=0.0)\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels([parse_task_name(task) for task in tasks], fontsize=10)\n",
    "    ax.set_ylabel('Distance to pretrained representation', fontsize=10)\n",
    "    ax.legend(fontsize=9)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_rsa_histogram_grid(compared_rdms, layer, tasks, only_diagonal=False):\n",
    "    sns.set_theme()\n",
    "    pretrained_color = sns.color_palette()[0]\n",
    "    finetuned_color = sns.color_palette()[1]\n",
    "\n",
    "    if only_diagonal:\n",
    "        first_task_rdms = compared_rdms[tasks[0]]\n",
    "        models = [model for model in first_task_rdms.keys() if 'pretrained' in model]\n",
    "        n_models = len(models)\n",
    "        n_tasks = len(tasks)\n",
    "        fig, axes = plt.subplots(n_models, n_tasks, figsize=(2 * n_tasks, 1.431 * n_models), squeeze=False,\n",
    "                                 sharex=True)\n",
    "\n",
    "        all_values = []\n",
    "        for model in models:\n",
    "            for task in tasks:\n",
    "                task_rdms = compared_rdms[task]\n",
    "                y_pretrained = f\"{model.split('_')[0]}_pretrained\"\n",
    "                y_finetuned = f\"{model.split('_')[0]}_tl\"\n",
    "                all_values.extend(task_rdms[model][y_pretrained][layer])\n",
    "                all_values.extend(task_rdms[model][y_finetuned][layer])\n",
    "        global_min = min(all_values)\n",
    "        global_max = max(all_values)\n",
    "        padding = (global_max - global_min) * 0.05\n",
    "        global_min -= padding\n",
    "        global_max += padding\n",
    "\n",
    "        for row, model in enumerate(models):\n",
    "            model_name = model.split('_')[0].capitalize()\n",
    "            if model_name == 'Bmi': model_name = 'BMI'\n",
    "            for col, task in enumerate(tasks):\n",
    "                ax = axes[row, col]\n",
    "                task_rdms = compared_rdms[task]\n",
    "                y_pretrained = f\"{model.split('_')[0]}_pretrained\"\n",
    "                y_finetuned = f\"{model.split('_')[0]}_tl\"\n",
    "                pretrained_data = task_rdms[model][y_pretrained][layer]\n",
    "                finetuned_data = task_rdms[model][y_finetuned][layer]\n",
    "                ax.axvline(x=1, color=pretrained_color, lw=2, alpha=0.7)\n",
    "                sns.kdeplot(finetuned_data, ax=ax, fill=True, alpha=0.5, color=finetuned_color,\n",
    "                            label=f'vs {y_finetuned}', linewidth=1, bw_adjust=0.8, legend=False)\n",
    "                ax.set_xlim(global_min, global_max)\n",
    "                ax.grid(alpha=0.5)\n",
    "                ax.set_yticks([])\n",
    "                if col == 0:\n",
    "                    ax.set_ylabel(f'{model_name} pretrained', fontsize=10)\n",
    "                else:\n",
    "                    ax.set_ylabel('')\n",
    "                    ax.set_yticklabels([])\n",
    "                if row == n_models - 1:\n",
    "                    ax.tick_params(axis='x', labelsize=9)\n",
    "                if row == 0:\n",
    "                    parsed_task_title = task.replace('ad_vs_hc', 'AD vs HC').replace('ad_vs_mci', 'AD vs MCI').replace('mci_vs_hc', 'MCI vs HC')\n",
    "                    ax.set_title(parsed_task_title, fontsize=10)\n",
    "                else:\n",
    "                    ax.set_title('')\n",
    "\n",
    "        handles = [\n",
    "            plt.Line2D([0], [0], color=pretrained_color, lw=4, alpha=0.7),\n",
    "            plt.Line2D([0], [0], color=finetuned_color, lw=4, alpha=0.7)\n",
    "        ]\n",
    "        labels = ['Pretrained', 'Fine-tuned']\n",
    "        fig.legend(handles, labels, fontsize=9, frameon=True, loc='lower right', ncol=2, columnspacing=0.8, handlelength=.1)\n",
    "        fig.supxlabel('Correlation value', fontsize=10)\n",
    "        plt.tight_layout(rect=[0.03, 0.03, 0.97, 0.95], pad=0)\n",
    "        return fig\n",
    "\n",
    "    if isinstance(tasks, str):\n",
    "        task = tasks\n",
    "    else:\n",
    "        task = tasks[0]\n",
    "    compared_rdms = compared_rdms[task]\n",
    "    x_models = [model for model in compared_rdms.keys() if 'pretrained' in model]\n",
    "    y_model_pairs = [(f'{y_model.split(\"_\")[0]}_pretrained', f'{y_model.split(\"_\")[0]}_tl') for y_model in x_models]\n",
    "\n",
    "    fig, axes = plt.subplots(len(y_model_pairs), len(x_models), figsize=(10, 8))\n",
    "    fig.tight_layout(pad=3.0)\n",
    "    plt.subplots_adjust(top=0.9)\n",
    "    parsed_task_title = task.replace('ad_vs_hc', 'AD and HC')\n",
    "    parsed_task_title = parsed_task_title.replace('ad_vs_mci', 'AD and MCI')\n",
    "    parsed_task_title = parsed_task_title.replace('mci_vs_hc', 'MCI and HC')\n",
    "    fig.suptitle(f'RSA Analysis on {parsed_task_title} subjects for layer {layer}', fontsize=14)\n",
    "\n",
    "    all_values = []\n",
    "    for x_model in x_models:\n",
    "        for y_pretrained, y_finetuned in y_model_pairs:\n",
    "            all_values.extend(compared_rdms[x_model][y_pretrained][layer])\n",
    "            all_values.extend(compared_rdms[x_model][y_finetuned][layer])\n",
    "    global_min = min(all_values)\n",
    "    global_max = max(all_values)\n",
    "    padding = (global_max - global_min) * 0.05\n",
    "    global_min -= padding\n",
    "    global_max += padding\n",
    "\n",
    "    for col, x_model in enumerate(x_models):\n",
    "        model_name = x_model.split('_')[0]\n",
    "        if model_name == 'bmi': model_name = 'BMI'\n",
    "        col_title = f'Similarity to {model_name} prediction model'\n",
    "        axes[0, col].set_title(col_title, fontsize=11)\n",
    "\n",
    "    for row, (pretrained, _) in enumerate(y_model_pairs):\n",
    "        model_name = pretrained.split('_')[0].capitalize()\n",
    "        if model_name == 'Bmi': model_name = 'BMI'\n",
    "        ylabel = f'{model_name} prediction\\n before and after fine-tuning'\n",
    "        axes[row, 0].set_ylabel(ylabel, fontsize=10)\n",
    "\n",
    "    fig.text(0.5, 0.02, 'Correlation value', ha='center', fontsize=14)\n",
    "    fig.text(0.02, 0.5, 'Similarity density', va='center', rotation='vertical', fontsize=14)\n",
    "\n",
    "    for row, (y_pretrained, y_finetuned) in enumerate(y_model_pairs):\n",
    "        for col, x_model in enumerate(x_models):\n",
    "            ax = axes[row, col]\n",
    "            ax.set_yticks([])\n",
    "            if col > 0:\n",
    "                ax.set_yticklabels([])\n",
    "            if row < len(y_model_pairs) - 1:\n",
    "                ax.set_xticks([])\n",
    "            else:\n",
    "                ax.tick_params(axis='x', labelsize=10)\n",
    "\n",
    "            pretrained_data = compared_rdms[x_model][y_pretrained][layer]\n",
    "            finetuned_data = compared_rdms[x_model][y_finetuned][layer]\n",
    "            if row != col:            \n",
    "                sns.kdeplot(pretrained_data, ax=ax, fill=True, alpha=0.5, color=pretrained_color,\n",
    "                            label=f'vs {y_pretrained}', linewidth=1, bw_adjust=0.8, legend=False)\n",
    "            else:\n",
    "                ax.axvline(x=1, color=pretrained_color, lw=2, alpha=0.7)\n",
    "            sns.kdeplot(finetuned_data, ax=ax, fill=True, alpha=0.5, color=finetuned_color,\n",
    "                        label=f'vs {y_finetuned}', linewidth=1, bw_adjust=0.8, legend=False)\n",
    "\n",
    "            ax.set_xlim(global_min, global_max)\n",
    "            ax.grid(alpha=0.3)\n",
    "\n",
    "    handles = [\n",
    "        plt.Line2D([0], [0], color=pretrained_color, lw=4, alpha=0.7),\n",
    "        plt.Line2D([0], [0], color=finetuned_color, lw=4, alpha=0.7)\n",
    "    ]\n",
    "    labels = ['Pretrained', 'Fine-tuned']\n",
    "    fig.legend(handles, labels, fontsize=10, frameon=True, loc='upper left')\n",
    "    plt.tight_layout(rect=[0.03, 0.03, 0.97, 0.95])\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PCA plotting methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_outliers(pretrained, finetuned, method='iqr', factor=1.5):\n",
    "    movement_distances = np.sqrt(np.sum((finetuned - pretrained)**2, axis=1))\n",
    "    \n",
    "    if method == 'iqr':\n",
    "        Q1 = np.percentile(movement_distances, 25)\n",
    "        Q3 = np.percentile(movement_distances, 75)\n",
    "        IQR = Q3 - Q1\n",
    "        lower_bound = Q1 - factor * IQR\n",
    "        upper_bound = Q3 + factor * IQR\n",
    "        mask = (movement_distances >= lower_bound) & (movement_distances <= upper_bound)\n",
    "    elif method == 'zscore':\n",
    "        z_scores = np.abs((movement_distances - np.mean(movement_distances)) / np.std(movement_distances))\n",
    "        mask = z_scores < factor\n",
    "    else:\n",
    "        raise ValueError(\"Method must be 'iqr' or 'zscore'\")\n",
    "    \n",
    "    return mask\n",
    "\n",
    "def get_task_labels():\n",
    "    \"\"\"Get class labels for each task.\"\"\"\n",
    "    return {\n",
    "        'ad_vs_hc': ('AD', 'HC'),\n",
    "        'ad_vs_mci': ('AD', 'MCI'), \n",
    "        'mci_vs_hc': ('MCI', 'HC')\n",
    "    }\n",
    "\n",
    "def get_model_colors():\n",
    "    \"\"\"Get color palette for different models.\"\"\"\n",
    "    return {\n",
    "        'age': '#E74C3C',      # Red\n",
    "        'bmi': '#3498DB',      # Blue  \n",
    "        'sex': '#2ECC71',      # Green\n",
    "        'none': '#9B59B6'      # Purple\n",
    "    }\n",
    "\n",
    "def get_modality_markers():\n",
    "    \"\"\"Get markers for different modalities.\"\"\"\n",
    "    return {'Pretrained': 'o', 'Finetuned': 's'}\n",
    "\n",
    "def get_class_colors():\n",
    "    \"\"\"Get colors for different classes.\"\"\"\n",
    "    return {'first': '#FF6B6B', 'second': '#4ECDC4'}\n",
    "\n",
    "def prepare_data(pcas, remove_outliers=False):\n",
    "    pretrained = pcas['pretrained']\n",
    "    finetuned = pcas['finetuned']\n",
    "    n_removed = 0\n",
    "    \n",
    "    if remove_outliers:\n",
    "        outlier_mask = detect_outliers(pretrained, finetuned)\n",
    "        pretrained = pretrained[outlier_mask]\n",
    "        finetuned = finetuned[outlier_mask]\n",
    "        n_removed = np.sum(~outlier_mask)\n",
    "    \n",
    "    return pretrained, finetuned, n_removed\n",
    "\n",
    "def plot_pca(tasks_pcas, model_name, save_path=None, remove_outliers=False):\n",
    "    task_labels = get_task_labels()\n",
    "    markers = get_modality_markers()\n",
    "    class_colors = get_class_colors()\n",
    "    \n",
    "    n_tasks = len(tasks_pcas)\n",
    "    fig, axes = plt.subplots(2, n_tasks, figsize=(5*n_tasks, 10))\n",
    "    if n_tasks == 1:\n",
    "        axes = axes.reshape(-1, 1)\n",
    "    \n",
    "    for idx, (task, models) in enumerate(tasks_pcas.items()):\n",
    "        if model_name not in models:\n",
    "            print(f\"Warning: Model '{model_name}' not found in task '{task}'. Skipping.\")\n",
    "            continue\n",
    "            \n",
    "        # Prepare data\n",
    "        pretrained, finetuned, n_removed = prepare_data(models[model_name], remove_outliers)\n",
    "        if n_removed > 0:\n",
    "            print(f\"Task {task}: Removed {n_removed} outliers from {model_name} model\")\n",
    "        \n",
    "        # Split data by class (first half vs second half)\n",
    "        n_samples = len(pretrained)\n",
    "        split_idx = n_samples // 2\n",
    "        class1_label, class2_label = task_labels.get(task, ('Class1', 'Class2'))\n",
    "        \n",
    "        pretrained_class1 = pretrained[:split_idx]\n",
    "        pretrained_class2 = pretrained[split_idx:]\n",
    "        finetuned_class1 = finetuned[:split_idx]\n",
    "        finetuned_class2 = finetuned[split_idx:]\n",
    "        \n",
    "        # Top row: Scatter plots comparing both conditions with class discrimination\n",
    "        ax_top = axes[0, idx]\n",
    "        \n",
    "        # Plot pretrained data with different colors for each class\n",
    "        ax_top.scatter(pretrained_class1[:, 0], pretrained_class1[:, 1], \n",
    "                      c=class_colors['first'], alpha=0.6, s=30, marker=markers['Pretrained'],\n",
    "                      label=f'Pretrained {class1_label}', edgecolors='white', linewidth=0.5)\n",
    "        ax_top.scatter(pretrained_class2[:, 0], pretrained_class2[:, 1], \n",
    "                      c=class_colors['second'], alpha=0.6, s=30, marker=markers['Pretrained'],\n",
    "                      label=f'Pretrained {class2_label}', edgecolors='white', linewidth=0.5)\n",
    "        \n",
    "        # Plot finetuned data with different colors for each class  \n",
    "        ax_top.scatter(finetuned_class1[:, 0], finetuned_class1[:, 1], \n",
    "                      c=class_colors['first'], alpha=0.6, s=30, marker=markers['Finetuned'],\n",
    "                      label=f'Finetuned {class1_label}', edgecolors='white', linewidth=0.5)\n",
    "        ax_top.scatter(finetuned_class2[:, 0], finetuned_class2[:, 1], \n",
    "                      c=class_colors['second'], alpha=0.6, s=30, marker=markers['Finetuned'],\n",
    "                      label=f'Finetuned {class2_label}', edgecolors='white', linewidth=0.5)\n",
    "        \n",
    "        ax_top.set_xlabel('PC1')\n",
    "        ax_top.set_ylabel('PC2')\n",
    "        ax_top.set_title(f'{task.upper()}: {model_name.upper()} PCA Comparison')\n",
    "        ax_top.legend()\n",
    "        ax_top.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Bottom row: Difference visualization (arrows showing movement)\n",
    "        ax_bottom = axes[1, idx]\n",
    "        \n",
    "        # Calculate movement vectors for both classes\n",
    "        movement_vectors_class1 = finetuned_class1 - pretrained_class1\n",
    "        movement_vectors_class2 = finetuned_class2 - pretrained_class2\n",
    "        \n",
    "        # Plot arrows showing the movement from pretrained to finetuned for each class\n",
    "        for i in range(len(pretrained_class1)):\n",
    "            ax_bottom.arrow(pretrained_class1[i, 0], pretrained_class1[i, 1],\n",
    "                           movement_vectors_class1[i, 0], movement_vectors_class1[i, 1],\n",
    "                           head_width=0.02, head_length=0.02, \n",
    "                           fc=class_colors['first'], ec=class_colors['first'], alpha=0.3, length_includes_head=True)\n",
    "        \n",
    "        for i in range(len(pretrained_class2)):\n",
    "            ax_bottom.arrow(pretrained_class2[i, 0], pretrained_class2[i, 1],\n",
    "                           movement_vectors_class2[i, 0], movement_vectors_class2[i, 1],\n",
    "                           head_width=0.02, head_length=0.02, \n",
    "                           fc=class_colors['second'], ec=class_colors['second'], alpha=0.3, length_includes_head=True)\n",
    "        \n",
    "        # Plot starting (pretrained) and ending (finetuned) points with class discrimination\n",
    "        ax_bottom.scatter(pretrained_class1[:, 0], pretrained_class1[:, 1], \n",
    "                         c=class_colors['first'], alpha=0.8, s=40, marker=markers['Pretrained'],\n",
    "                         label=f'Pretrained {class1_label}', edgecolors='white', linewidth=0.5)\n",
    "        ax_bottom.scatter(pretrained_class2[:, 0], pretrained_class2[:, 1], \n",
    "                         c=class_colors['second'], alpha=0.8, s=40, marker=markers['Pretrained'],\n",
    "                         label=f'Pretrained {class2_label}', edgecolors='white', linewidth=0.5)\n",
    "        ax_bottom.scatter(finetuned_class1[:, 0], finetuned_class1[:, 1], \n",
    "                         c=class_colors['first'], alpha=0.8, s=40, marker=markers['Finetuned'],\n",
    "                         label=f'Finetuned {class1_label}', edgecolors='white', linewidth=0.5)\n",
    "        ax_bottom.scatter(finetuned_class2[:, 0], finetuned_class2[:, 1], \n",
    "                         c=class_colors['second'], alpha=0.8, s=40, marker=markers['Finetuned'],\n",
    "                         label=f'Finetuned {class2_label}', edgecolors='white', linewidth=0.5)\n",
    "        \n",
    "        ax_bottom.set_xlabel('PC1')\n",
    "        ax_bottom.set_ylabel('PC2')\n",
    "        ax_bottom.set_title(f'{task.upper()}: {model_name.upper()} Movement Vectors')\n",
    "        ax_bottom.legend()\n",
    "        ax_bottom.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "        print(f\"Plot saved to {save_path}\")\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    return fig\n",
    "\n",
    "def plot_pca_models(tasks_pcas, task_name, model_names='all', save_path=None, remove_outliers=False):\n",
    "    if task_name not in tasks_pcas:\n",
    "        print(f\"Warning: Task '{task_name}' not found. Available tasks: {list(tasks_pcas.keys())}\")\n",
    "        return None\n",
    "    \n",
    "    model_colors = get_model_colors()\n",
    "    markers = get_modality_markers()\n",
    "    \n",
    "    models = tasks_pcas[task_name]\n",
    "    if model_names == 'all':\n",
    "        available_models = list(models.keys())\n",
    "    else:\n",
    "        available_models = [model_names] if isinstance(model_names, str) else list(model_names)\n",
    "    # Create single plot\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(10, 8))\n",
    "    \n",
    "    for model_name in available_models:\n",
    "        if model_name not in model_colors:\n",
    "            print(f\"Warning: No color defined for model '{model_name}'. Skipping.\")\n",
    "            continue\n",
    "            \n",
    "        # Get model color\n",
    "        base_color = model_colors[model_name]\n",
    "        \n",
    "        # Handle the 'none' model which only has finetuned data\n",
    "        if model_name == 'none':\n",
    "            # Only plot finetuned data for 'none' model\n",
    "            if 'finetuned' in models[model_name]:\n",
    "                finetuned_data = models[model_name]['finetuned']\n",
    "                \n",
    "                # Apply outlier removal if requested (compare with itself as baseline)\n",
    "                if remove_outliers:\n",
    "                    # For 'none' model, we can't use movement distance, so use position-based outliers\n",
    "                    distances_from_center = np.sqrt(np.sum((finetuned_data - np.mean(finetuned_data, axis=0))**2, axis=1))\n",
    "                    if len(distances_from_center) > 0:\n",
    "                        Q1 = np.percentile(distances_from_center, 25)\n",
    "                        Q3 = np.percentile(distances_from_center, 75)\n",
    "                        IQR = Q3 - Q1\n",
    "                        upper_bound = Q3 + 1.5 * IQR\n",
    "                        outlier_mask = distances_from_center <= upper_bound\n",
    "                        finetuned_data = finetuned_data[outlier_mask]\n",
    "                        n_removed = np.sum(~outlier_mask)\n",
    "                        if n_removed > 0:\n",
    "                            print(f\"Model {model_name}: Removed {n_removed} outliers\")\n",
    "                \n",
    "                # Plot only finetuned data\n",
    "                ax.scatter(finetuned_data[:, 0], finetuned_data[:, 1], \n",
    "                          c=base_color, alpha=0.8, s=30, marker=markers['Finetuned'],\n",
    "                          label=f'{model_name.upper()} (No Pretraining)', edgecolors='white', linewidth=0.5)\n",
    "        else:\n",
    "            # Handle regular models with both pretrained and finetuned data\n",
    "            # Prepare data\n",
    "            pretrained, finetuned, n_removed = prepare_data(models[model_name], remove_outliers)\n",
    "            if n_removed > 0:\n",
    "                print(f\"Model {model_name}: Removed {n_removed} outliers\")\n",
    "            \n",
    "            # Plot pretrained data\n",
    "            ax.scatter(pretrained[:, 0], pretrained[:, 1], \n",
    "                      c=base_color, alpha=0.6, s=30, marker=markers['Pretrained'],\n",
    "                      label=f'{model_name.upper()} Pretrained', edgecolors='white', linewidth=0.5)\n",
    "            \n",
    "            # Plot finetuned data\n",
    "            ax.scatter(finetuned[:, 0], finetuned[:, 1], \n",
    "                      c=base_color, alpha=0.8, s=30, marker=markers['Finetuned'],\n",
    "                      label=f'{model_name.upper()} Finetuned', edgecolors='white', linewidth=0.5)\n",
    "            \n",
    "            # Plot movement arrows (commented out to reduce clutter)\n",
    "            # movement_vectors = finetuned - pretrained\n",
    "            # for i in range(len(pretrained)):\n",
    "            #     ax.arrow(pretrained[i, 0], pretrained[i, 1],\n",
    "            #             movement_vectors[i, 0], movement_vectors[i, 1],\n",
    "            #             head_width=0.02, head_length=0.02, \n",
    "            #             fc=base_color, ec=base_color, alpha=0.2, length_includes_head=True)\n",
    "    \n",
    "    ax.set_xlabel('PC1')\n",
    "    ax.set_ylabel('PC2')\n",
    "    ax.set_title(f'{task_name.upper()}: All Models Comparison')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "        print(f\"Plot saved to {save_path}\")\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    return fig\n",
    "\n",
    "\n",
    "def plot_all_pcas(tasks_pcas, **kwargs):\n",
    "    # Get all available models from the first task\n",
    "    first_task = list(tasks_pcas.keys())[0]\n",
    "    available_models = list(tasks_pcas[first_task].keys())\n",
    "    \n",
    "    print(f\"Available models: {available_models}\")\n",
    "    \n",
    "    for model in available_models:\n",
    "        print(f\"\\nPlotting model: {model.upper()}\")\n",
    "        try:\n",
    "            plot_pca(tasks_pcas, model, **kwargs)\n",
    "        except Exception as e:\n",
    "            print(f\"Error plotting model '{model}': {e}\")\n",
    "\n",
    "\n",
    "def plot_all_tasks_pcas(tasks_pcas, **kwargs):\n",
    "    available_tasks = list(tasks_pcas.keys())\n",
    "    \n",
    "    print(f\"Available tasks: {available_tasks}\")\n",
    "    \n",
    "    for task in available_tasks:\n",
    "        print(f\"\\nPlotting models comparison for task: {task.upper()}\")\n",
    "        try:\n",
    "            plot_pca_models(tasks_pcas, task, **kwargs)\n",
    "        except Exception as e:\n",
    "            print(f\"Error plotting task '{task}': {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-23T15:03:21.316871Z",
     "start_time": "2025-06-23T15:03:18.497169Z"
    }
   },
   "outputs": [],
   "source": [
    "from pretrain_exp.rsa import compare_models, plot_maps, load_task_rdms\n",
    "from pathlib import Path\n",
    "\n",
    "base_path = Path('pretrain_exp')\n",
    "rdms_file, batches_file = 'rdms.pkl', 'batches.pkl'\n",
    "rdms_path = base_path / 'results'\n",
    "tasks = ['ad_vs_hc', 'ad_vs_mci', 'mci_vs_hc']\n",
    "models = ['age', 'sex', 'bmi', 'none']\n",
    "layers = ['conv0', 'conv1', 'conv2', 'conv3', 'conv4', 'conv5', 'fc6']\n",
    "ad_vs_hc_rdms, _ = load_task_rdms(rdms_path, 'ad_vs_hc')\n",
    "ad_vs_mci_rdms, _ = load_task_rdms(rdms_path, 'ad_vs_mci')\n",
    "mci_vs_hc_rdms, _ = load_task_rdms(rdms_path, 'mci_vs_hc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_iters = 100\n",
    "random_state = 42\n",
    "comparisons_dict = compare_models(tasks, models, layers, rdms_path, n_iters, random_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RDMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_ft_rdms = plot_maps(ad_vs_hc_rdms['age']['tl'], 'Age finetuned', ['AD', 'HC'], layers=layers + ['fc6'])\n",
    "age_ft_rdms = plot_maps(ad_vs_mci_rdms['age']['tl'], 'Age finetuned', ['AD', 'MCI'], layers=layers + ['fc6'])\n",
    "age_ft_rdms = plot_maps(mci_vs_hc_rdms['age']['tl'], 'Age finetuned', ['MCI', 'HC'], layers=layers + ['fc6'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pretrained comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_model_comparisons(comparisons_dict['ad_vs_hc'], model_type='pretrained', legend=False)\n",
    "# fig.savefig('ad_vs_hc_pretrained_comparisons.png', dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finetuned comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_model_comparisons(comparisons_dict['ad_vs_hc'], model_type='tl', layers=['conv1'], legend=True, \n",
    "                             x_label='Convolutional layer 1', title='Finetuned and non-pretrained modalities',\n",
    "                             fig_size=(10, 7.9))\n",
    "# fig.savefig('ad_vs_hc_tl_comparisons.png', dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Histogram similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import array, mean, abs, std\n",
    "layer = 'conv5'\n",
    "tasks = ['ad_vs_hc', 'ad_vs_mci', 'mci_vs_hc']\n",
    "representational_shifts = {}\n",
    "for task in tasks:\n",
    "    print(f'Task: {task}')\n",
    "    for model in comparisons_dict[task]:\n",
    "        if model.endswith('_tl'):\n",
    "            continue\n",
    "        model_name = model.split('_')[0]\n",
    "        if not model_name in representational_shifts:\n",
    "            representational_shifts[model_name] = {}\n",
    "        finetuned_model = model_name + '_tl'\n",
    "        comparison_with_self = array(comparisons_dict[task][model][model][layer])\n",
    "        comparison_with_finetuned = array(comparisons_dict[task][model][finetuned_model][layer])\n",
    "        representational_shift = abs(comparison_with_self - comparison_with_finetuned)\n",
    "        representational_shifts[model_name][task] = [mean(representational_shift), std(representational_shift)]\n",
    "        print(f'Model: {model_name}, Representational Shift: {mean(representational_shift):.6f} ± {std(representational_shift):.6f}')\n",
    "\n",
    "fig = plot_representational_shifts(representational_shifts)\n",
    "fig.patch.set_alpha(0)\n",
    "fig.savefig('representational_shifts.png', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_rsa_histogram_grid(comparisons_dict, layer='conv5', tasks=['ad_vs_hc', 'ad_vs_mci', 'mci_vs_hc'], only_diagonal=True)\n",
    "fig.patch.set_alpha(0)\n",
    "fig.savefig('rsa_histogram_grid.png', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer, task = 'conv5', 'ad_vs_hc'\n",
    "fig = plot_rsa_histogram_grid(comparisons_dict, layer, task)\n",
    "# fig.savefig(base_path / 'results' / f'rsa_histogram_{task}_{layer}.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA Convolutional layer 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "results_path = Path('pretrain_exp') / 'results'\n",
    "tasks = ['ad_vs_hc', 'ad_vs_mci', 'mci_vs_hc']\n",
    "tasks_pcas = {}\n",
    "for task in tasks:\n",
    "    with open(results_path / task / f'conv5_pcas.pkl', 'rb') as f:\n",
    "        tasks_pcas[task] = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Within model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_to_plot = 'age' \n",
    "figure = plot_pca(tasks_pcas, model_to_plot, save_path=f\"pca_{model_to_plot}.png\", remove_outliers=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Across models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_to_plot = 'mci_vs_hc'\n",
    "figure = plot_pca_models(tasks_pcas, task_to_plot,\n",
    "                         model_names='all',\n",
    "                         save_path=None, \n",
    "                         remove_outliers=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
